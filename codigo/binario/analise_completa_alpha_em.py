#!/usr/bin/env python3
"""
ANÃLISE CRÃTICA: Dataset completo 1B primos
Objetivo: Confirmar se nÃºmero de picos â‰ˆ 42-43 (logâ‚â‚€(Î±_EM/Î±_grav))
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.fft import fft, fftfreq
from scipy import signal

print("=" * 80)
print("ANÃLISE COMPLETA: 1 BILHÃƒO DE PRIMOS GÃŠMEOS")
print("Teste da HipÃ³tese: NÃºmero de picos â‰ˆ logâ‚â‚€(Î±_EM/Î±_grav) â‰ˆ 42.6")
print("=" * 80)

# Constantes
alpha_em = 1/137.035999084
alpha_grav_e = 1.751809e-45
log_ratio = np.log10(alpha_em / alpha_grav_e)

print(f"\nlogâ‚â‚€(Î±_EM/Î±_grav) = {log_ratio:.2f}")
print(f"PrediÃ§Ã£o: ~{log_ratio:.0f} picos significativos\n")

# Carregar dataset
print("Carregando dados...")
print("âš ï¸  AVISO: AnÃ¡lise de 1B primos pode levar 30-60 minutos")
print("           Usaremos amostragem estratificada para acelerar\n")

# EstratÃ©gia: Amostrar 100M primos uniformemente do 1B
TAMANHO_AMOSTRA = 100_000_000
STEP_AMOSTRAGEM = 10  # Pegar 1 a cada 10

try:
    # Ler com amostragem
    df = pd.read_csv('results_sorted_10M.csv', header=0)
    # NOTA: Como sÃ³ temos 10M ordenados, vamos usar isso como proxy
    # Para anÃ¡lise completa, precisarÃ­amos ordenar o dataset completo
    
    print(f"âš ï¸  Dataset disponÃ­vel: {len(df):,} primos")
    print(f"   Para anÃ¡lise completa, precisarÃ­amos de results_sorted_1B.csv")
    print(f"   Prosseguindo com 10M como demonstraÃ§Ã£o...\n")
    
    primos = df['p'].values
    
except Exception as e:
    print(f"Erro ao carregar: {e}")
    print("Tentando carregar results.csv (nÃ£o ordenado)...")
    
    # Tentar CSV nÃ£o ordenado
    df = pd.read_csv('results.csv', nrows=100_000_000, header=0)
    print(f"Carregados {len(df):,} primos (nÃ£o ordenados)")
    print("Ordenando...")
    df = df.sort_values('p')
    primos = df['p'].values

print(f"âœ“ Dataset: {len(primos):,} primos")
print(f"  Range: {primos.min():.3e} â†’ {primos.max():.3e}\n")

# AnÃ¡lise de densidade com janelas
WINDOW_SIZE = 10000
STEP = WINDOW_SIZE // 10

print("Calculando densidade local...")
posicoes = []
densidades = []

n_windows = (len(primos) - WINDOW_SIZE) // STEP

for i in range(0, len(primos) - WINDOW_SIZE, STEP):
    janela = primos[i:i+WINDOW_SIZE]
    posicoes.append(np.mean(janela))
    span = janela.max() - janela.min()
    if span > 0:
        densidades.append(WINDOW_SIZE / span)
    
    if (i // STEP) % 1000 == 0:
        progress = 100 * i / (len(primos) - WINDOW_SIZE)
        print(f"  Progresso: {progress:.1f}% ({i//STEP:,}/{n_windows:,} janelas)", end='\r')

print(f"\nâœ“ {len(posicoes):,} janelas analisadas")

posicoes = np.array(posicoes)
densidades = np.array(densidades)

print(f"  Densidade mÃ©dia: {np.mean(densidades):.6e}")
print(f"  CV: {np.std(densidades)/np.mean(densidades):.4f}\n")

# AnÃ¡lise espectral
print("Realizando FFT...")
dens_norm = (densidades - np.mean(densidades)) / np.std(densidades)
yf = fft(dens_norm)
xf = fftfreq(len(dens_norm), d=1.0)

mask = xf > 0
freqs = xf[mask]
power = np.abs(yf[mask])**2

print(f"âœ“ FFT completa: {len(freqs):,} frequÃªncias\n")

# Detectar picos com threshold variÃ¡vel
print("Detectando picos...")
print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
print("â”‚  Threshold  â”‚ Picos  â”‚ Significado â”‚")
print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")

for n_sigma in [3, 4, 5, 6, 7]:
    threshold = np.mean(power) + n_sigma * np.std(power)
    picos, _ = signal.find_peaks(power, height=threshold, distance=5)
    print(f"â”‚    {n_sigma}Ïƒ       â”‚  {len(picos):4d}  â”‚ {n_sigma}Ïƒ acima mÃ©dia â”‚")

print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n")

# Usar 3Ïƒ para contagem principal
threshold_3sigma = np.mean(power) + 3 * np.std(power)
picos_3sigma, _ = signal.find_peaks(power, height=threshold_3sigma, distance=5)

print(f"ğŸ¯ RESULTADO PRINCIPAL:")
print(f"   Picos detectados (3Ïƒ): {len(picos_3sigma)}")
print(f"   PrediÃ§Ã£o teÃ³rica: {log_ratio:.0f}")
print(f"   RazÃ£o: {len(picos_3sigma) / log_ratio:.3f}\n")

# AnÃ¡lise dos picos mais fortes
n_top = min(20, len(picos_3sigma))
idx_sorted = np.argsort(power[picos_3sigma])[::-1][:n_top]

print(f"Top {n_top} picos mais significativos:")
print("â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
print("â”‚ Rank â”‚  FrequÃªncia   â”‚   PerÃ­odo    â”‚   Ïƒ      â”‚")
print("â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")

for i, idx in enumerate(idx_sorted, 1):
    f = freqs[picos_3sigma[idx]]
    P = power[picos_3sigma[idx]]
    sigma = (P - np.mean(power)) / np.std(power)
    T = 1.0/f
    print(f"â”‚  {i:2d}  â”‚ {f:>13.6f} â”‚ {T:>12.1f} â”‚ {sigma:>8.1f} â”‚")

print("â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n")

# Verificar distribuiÃ§Ã£o de picos
print("DistribuiÃ§Ã£o de potÃªncia dos picos:")
potencias_picos = power[picos_3sigma]
print(f"  MÃ­nima: {potencias_picos.min():.2e}")
print(f"  Mediana: {np.median(potencias_picos):.2e}")
print(f"  MÃ¡xima: {potencias_picos.max():.2e}")
print(f"  RazÃ£o max/min: {potencias_picos.max()/potencias_picos.min():.1f}Ã—\n")

# VisualizaÃ§Ã£o
print("Gerando visualizaÃ§Ã£o...")
fig = plt.figure(figsize=(18, 12))

# 1. Densidade vs posiÃ§Ã£o
ax1 = plt.subplot(3, 3, 1)
step_plot = max(1, len(posicoes) // 10000)
ax1.plot(posicoes[::step_plot], densidades[::step_plot], 'b-', alpha=0.5, linewidth=0.3)
ax1.set_xlabel('PosiÃ§Ã£o')
ax1.set_ylabel('Densidade')
ax1.set_title(f'Densidade Local ({len(primos):,} primos)')
ax1.ticklabel_format(style='scientific', axis='x', scilimits=(0,0))
ax1.grid(True, alpha=0.3)

# 2. Densidade normalizada
ax2 = plt.subplot(3, 3, 2)
ax2.plot(dens_norm[::step_plot], 'g-', alpha=0.7, linewidth=0.3)
ax2.set_xlabel('Janela')
ax2.set_ylabel('Densidade norm (Ïƒ)')
ax2.set_title('FlutuaÃ§Ãµes (normalizado)')
ax2.axhline(0, color='k', linestyle='--', alpha=0.3)
ax2.grid(True, alpha=0.3)

# 3. Espectro completo (linear)
ax3 = plt.subplot(3, 3, 3)
ax3.plot(freqs, power, 'b-', alpha=0.5, linewidth=0.5)
ax3.plot(freqs[picos_3sigma], power[picos_3sigma], 'ro', markersize=4)
ax3.axhline(threshold_3sigma, color='r', linestyle='--', alpha=0.5, label='3Ïƒ')
ax3.set_xlabel('FrequÃªncia')
ax3.set_ylabel('PotÃªncia')
ax3.set_title(f'Espectro Completo ({len(picos_3sigma)} picos)')
ax3.legend()
ax3.grid(True, alpha=0.3)

# 4. Espectro (log)
ax4 = plt.subplot(3, 3, 4)
ax4.semilogy(freqs, power, 'b-', alpha=0.5, linewidth=0.5)
ax4.semilogy(freqs[picos_3sigma], power[picos_3sigma], 'ro', markersize=4)
ax4.axhline(threshold_3sigma, color='r', linestyle='--', alpha=0.5, label='3Ïƒ')
ax4.set_xlabel('FrequÃªncia')
ax4.set_ylabel('PotÃªncia (log)')
ax4.set_title('Espectro (escala log)')
ax4.legend()
ax4.grid(True, alpha=0.3)

# 5. Zoom nos picos mais fortes
ax5 = plt.subplot(3, 3, 5)
top5_indices = idx_sorted[:5]
for i, idx in enumerate(top5_indices):
    f_peak = freqs[picos_3sigma[idx]]
    # Janela ao redor do pico
    mask_zoom = (freqs > f_peak*0.9) & (freqs < f_peak*1.1)
    ax5.plot(freqs[mask_zoom], power[mask_zoom], alpha=0.7, label=f'Pico {i+1}')
ax5.set_xlabel('FrequÃªncia')
ax5.set_ylabel('PotÃªncia')
ax5.set_title('Zoom: Top 5 Picos')
ax5.legend()
ax5.grid(True, alpha=0.3)

# 6. DistribuiÃ§Ã£o de significÃ¢ncias
ax6 = plt.subplot(3, 3, 6)
sigmas = (power[picos_3sigma] - np.mean(power)) / np.std(power)
ax6.hist(sigmas, bins=30, alpha=0.7, edgecolor='black')
ax6.axvline(log_ratio, color='r', linestyle='--', linewidth=2, label=f'log(Î±_EM/Î±_grav)={log_ratio:.1f}')
ax6.set_xlabel('SignificÃ¢ncia (Ïƒ)')
ax6.set_ylabel('FrequÃªncia')
ax6.set_title(f'DistribuiÃ§Ã£o de SignificÃ¢ncias')
ax6.legend()
ax6.grid(True, alpha=0.3)

# 7. NÃºmero de picos vs threshold
ax7 = plt.subplot(3, 3, 7)
thresholds = np.arange(2, 10, 0.5)
n_picos_vs_thresh = []
for th in thresholds:
    threshold_i = np.mean(power) + th * np.std(power)
    picos_i, _ = signal.find_peaks(power, height=threshold_i, distance=5)
    n_picos_vs_thresh.append(len(picos_i))

ax7.plot(thresholds, n_picos_vs_thresh, 'bo-', linewidth=2, markersize=6)
ax7.axhline(log_ratio, color='r', linestyle='--', linewidth=2, label=f'{log_ratio:.0f} (prediÃ§Ã£o)')
ax7.set_xlabel('Threshold (Ïƒ)')
ax7.set_ylabel('NÃºmero de Picos')
ax7.set_title('Picos vs Threshold')
ax7.legend()
ax7.grid(True, alpha=0.3)

# 8. EspaÃ§amento entre picos
ax8 = plt.subplot(3, 3, 8)
freq_picos = freqs[picos_3sigma]
spacings = np.diff(sorted(freq_picos))
ax8.hist(spacings, bins=30, alpha=0.7, edgecolor='black')
ax8.set_xlabel('Î”f entre picos')
ax8.set_ylabel('FrequÃªncia')
ax8.set_title('EspaÃ§amento entre Picos')
ax8.grid(True, alpha=0.3)

# 9. AnÃ¡lise de razÃ£o
ax9 = plt.subplot(3, 3, 9)
n_picos_range = [8, len(picos_3sigma)]  # 1M vs atual
tamanho_range = [1e6, len(primos)]
ax9.loglog(tamanho_range, n_picos_range, 'go-', linewidth=2, markersize=10, label='Observado')
# ProjeÃ§Ã£o para 1B
if len(primos) < 1e9:
    taxa = np.log(n_picos_range[1]/n_picos_range[0]) / np.log(tamanho_range[1]/tamanho_range[0])
    n_1B = n_picos_range[1] * (1e9/tamanho_range[1])**taxa
    ax9.loglog([tamanho_range[1], 1e9], [n_picos_range[1], n_1B], 'r--', linewidth=2, label=f'ProjeÃ§Ã£oâ†’{n_1B:.0f}')
ax9.axhline(log_ratio, color='orange', linestyle='--', linewidth=2, label=f'Î±_EM/Î±_grav={log_ratio:.0f}')
ax9.set_xlabel('Tamanho do Dataset')
ax9.set_ylabel('NÃºmero de Picos')
ax9.set_title('Scaling: Picos vs Tamanho')
ax9.legend()
ax9.grid(True, alpha=0.3, which='both')

plt.tight_layout()
plt.savefig('analise_completa_alpha_em.png', dpi=150, bbox_inches='tight')
print(f"âœ“ Salvo: analise_completa_alpha_em.png\n")

# RelatÃ³rio final
print("=" * 80)
print("RESULTADO FINAL: TESTE DA HIPÃ“TESE Î±_EM")
print("=" * 80)

print(f"""
Dataset analisado: {len(primos):,} primos gÃªmeos
Janelas: {len(posicoes):,}

PICOS DETECTADOS (3Ïƒ):
  Observado: {len(picos_3sigma)} picos
  PrediÃ§Ã£o:  {log_ratio:.0f} picos (logâ‚â‚€(Î±_EM/Î±_grav))
  RazÃ£o:     {len(picos_3sigma)/log_ratio:.3f}
  
ANÃLISE:
""")

if abs(len(picos_3sigma) - log_ratio) < 5:
    print("  âœ… CONCORDÃ‚NCIA EXCELENTE!")
    print("     NÃºmero de picos consistente com hierarquia Î±_EM/Î±_grav")
elif abs(len(picos_3sigma) - log_ratio) < 10:
    print("  âœ… CONCORDÃ‚NCIA BOA")
    print("     Desvio aceitÃ¡vel (< 10 picos)")
elif len(picos_3sigma) < log_ratio:
    print("  âš ï¸  MENOS PICOS QUE O ESPERADO")
    print(f"     DiferenÃ§a: {log_ratio - len(picos_3sigma):.0f} picos")
    print("     PossÃ­vel razÃ£o: Dataset ainda pequeno")
    taxa = np.log(len(picos_3sigma)/8) / np.log(len(primos)/1e6)
    n_projetado_1B = len(picos_3sigma) * (1e9/len(primos))**taxa
    print(f"     ProjeÃ§Ã£o para 1B: {n_projetado_1B:.0f} picos")
else:
    print("  âš ï¸  MAIS PICOS QUE O ESPERADO")
    print(f"     DiferenÃ§a: {len(picos_3sigma) - log_ratio:.0f} picos")
    print("     PossÃ­vel razÃ£o: Threshold 3Ïƒ capturando ruÃ­do")

print("\n" + "=" * 80)
