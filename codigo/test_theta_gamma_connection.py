#!/usr/bin/env python3
"""
Conex√£o Anal√≠tica: Œ∏ (OU) ‚Üî Œ≥ (Euler-Mascheroni) ‚Üî Zeros de Riemann

F√≥rmulas dos zeros:
- Riemann-von Mangoldt: Œ∏(t) = Im(log Œì(1/4 + it/2)) - t¬∑log(œÄ)/2
- Gap m√©dio assint√≥tico: Œît_n ‚âà 2œÄ / log(t_n/(2œÄ))
- t_n ‚âà 2œÄn / log n (aproxima√ß√£o de Gram)

Hip√≥tese: Œ∏_OU relaciona-se com Œ≥ via f√≥rmulas anal√≠ticas
"""

import numpy as np
import json
import matplotlib.pyplot as plt
from scipy.special import digamma, loggamma
from scipy.optimize import curve_fit

print("=" * 70)
print("CONEX√ÉO ANAL√çTICA: Œ∏ (OU) ‚Üî Œ≥ (Euler) ‚Üî Zeros de Riemann")
print("=" * 70)

# Constantes
gamma_euler = 0.5772156649015329  # Constante de Euler-Mascheroni
pi = np.pi

print(f"\n[CONSTANTES]")
print(f"  Œ≥ (Euler-Mascheroni) = {gamma_euler:.10f}")
print(f"  œÄ = {pi:.10f}")

# Carregar zeros de Riemann
with open('/home/thlinux/relacionalidadegeral/validacao/riemann_extended_analysis.json', 'r') as f:
    data = json.load(f)

zeros = np.array(data['zeros'])
gaps = np.diff(zeros)
n_zeros = len(zeros)

print(f"\n[DADOS]")
print(f"  N√∫mero de zeros: {len(zeros)}")
print(f"  Range: [{zeros[0]:.2f}, {zeros[-1]:.2f}]")
print(f"  Gap m√©dio: {np.mean(gaps):.4f}")
print(f"  Gap std: {np.std(gaps):.4f}")

# F√≥rmulas te√≥ricas dos zeros
def riemann_von_mangoldt_theta(t):
    """Œ∏(t) = Im(log Œì(1/4 + it/2)) - t¬∑log(œÄ)/2"""
    # Aproxima√ß√£o usando digamma
    z = 0.25 + 1j * t / 2
    # log Œì(z) aproximado para |z| grande
    log_gamma_approx = (z - 0.5) * np.log(z) - z + 0.5 * np.log(2*pi)
    theta = log_gamma_approx.imag - t * np.log(pi) / 2
    return theta

def asymptotic_gap(t):
    """Gap m√©dio assint√≥tico: 2œÄ / log(t/(2œÄ))"""
    return 2 * pi / np.log(t / (2*pi))

def gram_point_formula(n):
    """Aproxima√ß√£o t_n ‚âà 2œÄn / log n"""
    return 2 * pi * n / np.log(n) if n > 1 else 1.0

# Calcular valores te√≥ricos
print(f"\n{'=' * 70}")
print("F√ìRMULAS TE√ìRICAS DOS ZEROS")
print(f"{'=' * 70}")

# Para cada zero, calcular f√≥rmulas
theta_values = []
asymptotic_gaps_pred = []
gram_approx = []

for i, t in enumerate(zeros):
    n = i + 1

    # Œ∏(t) de Riemann-von Mangoldt
    theta_t = riemann_von_mangoldt_theta(t)
    theta_values.append(theta_t)

    # Gap assint√≥tico
    if t > 2*pi:
        gap_asym = asymptotic_gap(t)
    else:
        gap_asym = np.nan
    asymptotic_gaps_pred.append(gap_asym)

    # Gram approximation
    t_gram = gram_point_formula(n)
    gram_approx.append(t_gram)

theta_values = np.array(theta_values)
asymptotic_gaps_pred = np.array(asymptotic_gaps_pred)
gram_approx = np.array(gram_approx)

# Comparar gaps reais vs assint√≥ticos
valid_idx = ~np.isnan(asymptotic_gaps_pred[:-1])
gap_error = np.abs(gaps[valid_idx] - asymptotic_gaps_pred[:-1][valid_idx])

print(f"\n[COMPARA√á√ÉO: Gaps Reais vs Assint√≥ticos]")
print(f"  MAE (erro m√©dio absoluto): {np.mean(gap_error):.4f}")
print(f"  RMSE: {np.sqrt(np.mean(gap_error**2)):.4f}")
print(f"  Correla√ß√£o: {np.corrcoef(gaps[valid_idx], asymptotic_gaps_pred[:-1][valid_idx])[0,1]:.4f}")

# CONEX√ÉO COM Œ∏ DO PROCESSO OU
print(f"\n{'=' * 70}")
print("CONEX√ÉO COM Œ∏ DO PROCESSO OU")
print(f"{'=' * 70}")

# Hip√≥tese 1: Œ∏_OU relacionado com gap m√©dio assint√≥tico
gap_mean_empirical = np.mean(gaps)
gap_mean_asymptotic = np.mean(asymptotic_gaps_pred[~np.isnan(asymptotic_gaps_pred)])

# Œ∏_OU = 1 √© o que usamos
theta_ou_used = 1.0

# Tentar relacionar Œ∏_OU com f√≥rmulas
# Hip√≥tese: Œ∏_OU ~ 1/gap_mean (tempo caracter√≠stico de revers√£o)
theta_ou_predicted_1 = 1.0 / gap_mean_empirical
print(f"\n[HIP√ìTESE 1: Œ∏_OU ~ 1/gap_mean]")
print(f"  Œ∏_OU usado: {theta_ou_used}")
print(f"  Œ∏_OU previsto: {theta_ou_predicted_1:.4f}")
print(f"  Raz√£o: {theta_ou_used / theta_ou_predicted_1:.4f}")

# Hip√≥tese 2: Œ∏_OU relacionado com Œ≥
# Œ∏_OU ~ Œ≥ √ó constante
theta_ou_predicted_2 = gamma_euler * (2*pi / gap_mean_empirical)
print(f"\n[HIP√ìTESE 2: Œ∏_OU ~ Œ≥ √ó (2œÄ/gap_mean)]")
print(f"  Œ∏_OU usado: {theta_ou_used}")
print(f"  Œ∏_OU previsto: {theta_ou_predicted_2:.4f}")
print(f"  Raz√£o: {theta_ou_used / theta_ou_predicted_2:.4f}")

# Hip√≥tese 3: Rela√ß√£o via Œ∏(t) de Riemann-von Mangoldt
# Œ∏_OU ~ varia√ß√£o de Œ∏(t)
theta_diffs = np.diff(theta_values)
theta_ou_predicted_3 = np.std(theta_diffs) / gap_mean_empirical
print(f"\n[HIP√ìTESE 3: Œ∏_OU ~ std(ŒîŒ∏(t)) / gap_mean]")
print(f"  Œ∏_OU usado: {theta_ou_used}")
print(f"  Œ∏_OU previsto: {theta_ou_predicted_3:.4f}")
print(f"  Raz√£o: {theta_ou_used / theta_ou_predicted_3:.4f}")

# Hip√≥tese 4: Conex√£o via Œ≥ e log
# Inspirado em: gap ~ 2œÄ/log(t), Œ∏_OU ~ Œ≥/log(gap)
mean_log_t = np.mean(np.log(zeros))
theta_ou_predicted_4 = gamma_euler / np.log(gap_mean_empirical + 1)
print(f"\n[HIP√ìTESE 4: Œ∏_OU ~ Œ≥ / log(gap_mean + 1)]")
print(f"  Œ∏_OU usado: {theta_ou_used}")
print(f"  Œ∏_OU previsto: {theta_ou_predicted_4:.4f}")
print(f"  Raz√£o: {theta_ou_used / theta_ou_predicted_4:.4f}")

# TESTAR PROCESSO OU COM Œ∏ DERIVADO DAS F√ìRMULAS
print(f"\n{'=' * 70}")
print("TESTE: OU COM Œ∏ DERIVADO DAS F√ìRMULAS DE RIEMANN")
print(f"{'=' * 70}")

# Distribui√ß√£o real
gap_analysis = data['gap_analysis']
level_dist_real = gap_analysis['level_distribution']
total_real = sum(level_dist_real.values())
P_real = {int(k): v/total_real for k, v in level_dist_real.items()}

def test_ou_with_theta(theta_ou, name):
    """Testar processo OU com Œ∏ espec√≠fico"""
    mu = gap_mean_empirical
    sigma_ou = np.std(gaps) * 0.5
    sigma_noise = np.std(gaps) * 0.5
    n_steps = 10000
    dt = 0.01

    # Gerar OU
    X = np.zeros(n_steps)
    X[0] = mu

    for i in range(1, n_steps):
        dX_ou = theta_ou * (mu - X[i-1]) * dt
        dW_ou = sigma_ou * np.sqrt(dt) * np.random.randn()
        dW_noise = sigma_noise * np.sqrt(dt) * np.random.randn()
        X[i] = X[i-1] + dX_ou + dW_ou + dW_noise
        X[i] = max(0.01, X[i])

    # Analisar distribui√ß√£o
    normalized = X / np.mean(X)
    normalized = np.clip(normalized, 1e-10, None)
    levels = np.floor(np.log2(normalized)).astype(int)
    unique_levels, counts = np.unique(levels, return_counts=True)
    P_emergent = {int(lv): cnt/len(levels) for lv, cnt in zip(unique_levels, counts)}

    # Chi-squared vs Riemann
    chi2 = 0
    for level in P_real.keys():
        obs = P_emergent.get(level, 0)
        exp = P_real[level]
        if exp > 0:
            chi2 += (obs - exp)**2 / exp

    accuracy = max(0, 1 - chi2/10.0) * 100

    print(f"\n  {name}")
    print(f"    Œ∏_OU = {theta_ou:.4f}")
    print(f"    Accuracy vs Riemann: {accuracy:.2f}%")
    print(f"    œá¬≤ = {chi2:.4f}")

    return accuracy, P_emergent

# Testar diferentes Œ∏
results = {}

results['baseline'] = test_ou_with_theta(1.0, "[BASELINE] Œ∏ = 1.0")
results['hyp1'] = test_ou_with_theta(theta_ou_predicted_1, "[HIP 1] Œ∏ ~ 1/gap_mean")
results['hyp2'] = test_ou_with_theta(theta_ou_predicted_2, "[HIP 2] Œ∏ ~ Œ≥ √ó (2œÄ/gap)")
results['hyp4'] = test_ou_with_theta(theta_ou_predicted_4, "[HIP 4] Œ∏ ~ Œ≥ / log(gap)")

# Testar tamb√©m Œ∏ = Œ≥ diretamente
results['gamma'] = test_ou_with_theta(gamma_euler, "[DIRETO] Œ∏ = Œ≥")

# Gr√°ficos
fig, axes = plt.subplots(2, 3, figsize=(16, 10))

# 1. Zeros e Gram approximation
ax1 = axes[0, 0]
n_range = np.arange(1, len(zeros)+1)
ax1.plot(n_range, zeros, 'b.', markersize=3, alpha=0.5, label='Zeros reais')
ax1.plot(n_range, gram_approx, 'r-', linewidth=2, alpha=0.7, label='Gram approx')
ax1.set_xlabel('n', fontsize=12)
ax1.set_ylabel('t_n', fontsize=12)
ax1.set_title('Zeros vs Aproxima√ß√£o de Gram', fontsize=13, fontweight='bold')
ax1.legend()
ax1.grid(True, alpha=0.3)

# 2. Gaps reais vs assint√≥ticos
ax2 = axes[0, 1]
ax2.scatter(zeros[:-1][valid_idx], gaps[valid_idx], s=10, alpha=0.3, label='Gaps reais')
ax2.plot(zeros[:-1][valid_idx], asymptotic_gaps_pred[:-1][valid_idx], 'r-',
         linewidth=2, alpha=0.7, label='2œÄ/log(t/2œÄ)')
ax2.set_xlabel('t', fontsize=12)
ax2.set_ylabel('Gap', fontsize=12)
ax2.set_title('Gaps Reais vs F√≥rmula Assint√≥tica', fontsize=13, fontweight='bold')
ax2.legend()
ax2.grid(True, alpha=0.3)

# 3. Œ∏(t) de Riemann-von Mangoldt
ax3 = axes[0, 2]
ax3.plot(zeros, theta_values, 'purple', linewidth=1.5)
ax3.set_xlabel('t', fontsize=12)
ax3.set_ylabel('Œ∏(t)', fontsize=12)
ax3.set_title('Œ∏(t) de Riemann-von Mangoldt', fontsize=13, fontweight='bold')
ax3.grid(True, alpha=0.3)

# 4. Accuracy por hip√≥tese
ax4 = axes[1, 0]
labels = ['Baseline\nŒ∏=1', 'Hip 1\n1/gap', 'Hip 2\nŒ≥√ó2œÄ/gap', 'Hip 4\nŒ≥/log', 'Direto\nŒ∏=Œ≥']
accs = [results[k][0] for k in ['baseline', 'hyp1', 'hyp2', 'hyp4', 'gamma']]
colors = ['blue', 'orange', 'green', 'purple', 'red']
bars = ax4.bar(labels, accs, color=colors, alpha=0.7)
ax4.axhline(90, color='gray', linestyle='--', linewidth=2, alpha=0.5)
ax4.set_ylabel('Accuracy vs Riemann (%)', fontsize=12)
ax4.set_title('Compara√ß√£o de Hip√≥teses para Œ∏', fontsize=13, fontweight='bold')
ax4.grid(True, alpha=0.3, axis='y')
ax4.set_ylim([0, 100])

# Adicionar valores
for bar, acc in zip(bars, accs):
    height = bar.get_height()
    ax4.text(bar.get_x() + bar.get_width()/2., height,
             f'{acc:.1f}%', ha='center', va='bottom', fontsize=10, fontweight='bold')

# 5. Distribui√ß√µes emergentes
ax5 = axes[1, 1]
riemann_levels = sorted(P_real.keys())
riemann_probs = [P_real[k] for k in riemann_levels]
ax5.plot(riemann_levels, riemann_probs, 'k^--', linewidth=3, markersize=8,
         label='Riemann', alpha=0.8)

for key, color, label in [('baseline', 'blue', 'Œ∏=1'), ('gamma', 'red', 'Œ∏=Œ≥')]:
    P_em = results[key][1]
    levels_em = sorted(P_em.keys())
    probs_em = [P_em[k] for k in levels_em]
    ax5.plot(levels_em, probs_em, 'o-', color=color, linewidth=2,
             markersize=6, label=label, alpha=0.7)

ax5.set_xlabel('Level k', fontsize=12)
ax5.set_ylabel('P(k)', fontsize=12)
ax5.set_title('Distribui√ß√µes: Œ∏=1 vs Œ∏=Œ≥', fontsize=13, fontweight='bold')
ax5.legend(fontsize=10)
ax5.grid(True, alpha=0.3)
ax5.set_yscale('log')

# 6. Raz√µes Œ∏_previsto / Œ∏_usado
ax6 = axes[1, 2]
theta_predictions = [1.0, theta_ou_predicted_1, theta_ou_predicted_2,
                     theta_ou_predicted_4, gamma_euler]
ratios = [t / theta_ou_used for t in theta_predictions]
ax6.barh(labels, ratios, color=colors, alpha=0.7)
ax6.axvline(1.0, color='black', linestyle='--', linewidth=2, label='Œ∏ usado (1.0)')
ax6.set_xlabel('Raz√£o: Œ∏_previsto / Œ∏_usado', fontsize=12)
ax6.set_title('Predi√ß√µes de Œ∏_OU', fontsize=13, fontweight='bold')
ax6.legend()
ax6.grid(True, alpha=0.3, axis='x')

plt.tight_layout()
plt.savefig('/home/thlinux/relacionalidadegeral/validacao/theta_gamma_connection.png',
            dpi=300, bbox_inches='tight')
print(f"\n‚úì Gr√°fico salvo: validacao/theta_gamma_connection.png")

# Salvar an√°lise
output = {
    'constants': {
        'gamma_euler': gamma_euler,
        'pi': pi
    },
    'gap_statistics': {
        'mean_empirical': float(gap_mean_empirical),
        'mean_asymptotic': float(gap_mean_asymptotic),
        'std_empirical': float(np.std(gaps))
    },
    'theta_predictions': {
        'baseline': 1.0,
        'hypothesis_1_1_over_gap': float(theta_ou_predicted_1),
        'hypothesis_2_gamma_times_2pi_over_gap': float(theta_ou_predicted_2),
        'hypothesis_4_gamma_over_log_gap': float(theta_ou_predicted_4),
        'direct_gamma': gamma_euler
    },
    'accuracies': {
        'baseline': float(results['baseline'][0]),
        'hypothesis_1': float(results['hyp1'][0]),
        'hypothesis_2': float(results['hyp2'][0]),
        'hypothesis_4': float(results['hyp4'][0]),
        'direct_gamma': float(results['gamma'][0])
    }
}

with open('/home/thlinux/relacionalidadegeral/validacao/theta_gamma_connection_results.json', 'w') as f:
    json.dump(output, f, indent=2)

print(f"‚úì An√°lise salva: validacao/theta_gamma_connection_results.json")

print(f"\n{'=' * 70}")
print("CONCLUS√ÉO")
print(f"{'=' * 70}")

best_key = max(results.keys(), key=lambda k: results[k][0])
best_acc = results[best_key][0]

print(f"\n[MELHOR RESULTADO]")
if best_key == 'baseline':
    print(f"  Œ∏ = 1.0 (baseline) permanece o melhor: {best_acc:.2f}%")
elif best_key == 'gamma':
    print(f"  Œ∏ = Œ≥ ({gamma_euler:.4f}) √â MELHOR! Accuracy: {best_acc:.2f}%")
    print(f"  üî• CONEX√ÉO DIRETA Œ≥ ‚Üî Œ∏_OU VALIDADA!")
else:
    print(f"  Melhor hip√≥tese: {best_key}")
    print(f"  Accuracy: {best_acc:.2f}%")

print(f"\n[INTERPRETA√á√ÉO]")
print(f"  A constante Œ≥ de Euler-Mascheroni aparece nas f√≥rmulas")
print(f"  assint√≥ticas dos zeros de Riemann. Nossos testes mostram:")
print(f"  ‚Ä¢ Œ∏=1.0 ‚Üí {results['baseline'][0]:.2f}%")
print(f"  ‚Ä¢ Œ∏=Œ≥ ‚Üí {results['gamma'][0]:.2f}%")

if abs(results['gamma'][0] - results['baseline'][0]) < 2:
    print(f"\n  Resultados SIMILARES! Œ≥ e 1.0 s√£o compar√°veis.")
    print(f"  Diferen√ßa: {abs(results['gamma'][0] - results['baseline'][0]):.2f}%")
elif results['gamma'][0] > results['baseline'][0]:
    print(f"\n  Œ∏=Œ≥ √â MELHOR! Ganho de {results['gamma'][0] - results['baseline'][0]:.2f}%")
else:
    print(f"\n  Œ∏=1.0 ainda √© melhor que Œ∏=Œ≥")

print(f"\n{'=' * 70}\n")
