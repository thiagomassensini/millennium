#!/usr/bin/env python3
"""
AR(3) + Distribui√ß√£o de Boltzmann
Tentar quebrar barreira de 98% e chegar em 99%

Estrat√©gias testadas:
1. AR(3) + Boltzmann energy-based noise
2. AR(3) + Boltzmann state transitions
3. AR(3) puro (sem OU) + Boltzmann
4. Varia√ß√µes de temperatura T
"""

import numpy as np
import json
import matplotlib.pyplot as plt
from scipy.optimize import differential_evolution

print("=" * 70)
print("AR(3) + DISTRIBUI√á√ÉO DE BOLTZMANN")
print("Tentativa de chegar em 99% accuracy")
print("=" * 70)

# Carregar dados de Riemann
with open('/home/thlinux/relacionalidadegeral/validacao/riemann_extended_analysis.json', 'r') as f:
    data_riemann = json.load(f)

zeros = np.array(data_riemann['zeros'])
gaps = np.diff(zeros)
gap_mean = np.mean(gaps)

# Distribui√ß√£o alvo
gap_analysis = data_riemann['gap_analysis']
level_dist_riemann = gap_analysis['level_distribution']
total_riemann = sum(level_dist_riemann.values())
P_target = {int(k): v/total_riemann for k, v in level_dist_riemann.items()}

print(f"\n[TARGET] Distribui√ß√£o de Riemann:")
for level in sorted(P_target.keys()):
    if P_target[level] > 0.001:
        print(f"  Level {level}: {100*P_target[level]:.1f}%")

# FUN√á√ÉO: Simular AR(3) com Boltzmann
def simulate_ar3_boltzmann(phi_params, mu, sigma_noise, temperature, boltzmann_mode, n_steps=10000):
    """
    AR(3) com distribui√ß√£o de Boltzmann

    boltzmann_mode:
    1 = Energy-based noise modulation
    2 = Boltzmann state transitions
    3 = Pure AR(3) (no OU) with Boltzmann weights
    4 = Level-dependent energy landscape
    """
    X = np.zeros(n_steps)
    X[:3] = mu

    for t in range(3, n_steps):
        # Termo AR(3)
        ar_term = sum(phi_params[i] * (X[t-1-i] - mu) for i in range(3))

        if boltzmann_mode == 1:
            # MODE 1: Energy-based noise modulation
            # Energia baseada no desvio da m√©dia
            current_deviation = abs(X[t-1] - mu)
            energy = current_deviation / mu  # Energia normalizada
            boltzmann_factor = np.exp(-energy / temperature)

            noise = sigma_noise * boltzmann_factor * np.random.randn()
            X[t] = mu + ar_term + noise

        elif boltzmann_mode == 2:
            # MODE 2: Boltzmann state transitions
            # Calcular level atual
            current_level = np.floor(np.log2(max(X[t-1], 0.01) / mu))

            # Propor novo estado
            noise = sigma_noise * np.random.randn()
            X_proposed = mu + ar_term + noise
            X_proposed = max(0.01, X_proposed)
            proposed_level = np.floor(np.log2(X_proposed / mu))

            # Energia baseada na probabilidade da distribui√ß√£o alvo
            def level_energy(lv):
                prob = P_target.get(int(lv), 1e-10)
                return -np.log(prob)  # E = -log(P)

            E_current = level_energy(current_level)
            E_proposed = level_energy(proposed_level)
            delta_E = E_proposed - E_current

            # Metropolis-Hastings acceptance
            if delta_E < 0 or np.random.rand() < np.exp(-delta_E / temperature):
                X[t] = X_proposed
            else:
                X[t] = X[t-1]

        elif boltzmann_mode == 3:
            # MODE 3: Pure AR(3) without mean reversion, Boltzmann weights
            # N√£o usar Œº como centro, deixar o processo livre
            ar_term_pure = sum(phi_params[i] * X[t-1-i] for i in range(3))

            # Ru√≠do modulado por Boltzmann baseado no hist√≥rico
            recent_variance = np.var(X[max(0, t-10):t])
            energy = recent_variance / (mu**2)  # Energia baseada na vari√¢ncia local
            boltzmann_factor = np.exp(-energy / temperature)

            noise = sigma_noise * boltzmann_factor * np.random.randn()
            X[t] = ar_term_pure + noise
            X[t] = max(0.01, X[t])

        elif boltzmann_mode == 4:
            # MODE 4: Level-dependent energy landscape
            # Criar "potencial" que favorece certos levels
            noise = sigma_noise * np.random.randn()
            X_candidate = mu + ar_term + noise
            X_candidate = max(0.01, X_candidate)

            candidate_level = np.floor(np.log2(X_candidate / mu))

            # Energia favorece levels com alta probabilidade em P_target
            target_prob = P_target.get(int(candidate_level), 1e-10)
            energy = -np.log(target_prob)

            # Aceitar com probabilidade de Boltzmann
            acceptance_prob = np.exp(-energy / temperature)

            if np.random.rand() < acceptance_prob:
                X[t] = X_candidate
            else:
                # Se rejeitar, adicionar ru√≠do menor
                X[t] = X[t-1] + 0.1 * sigma_noise * np.random.randn()
                X[t] = max(0.01, X[t])

        else:
            raise ValueError(f"Invalid boltzmann_mode: {boltzmann_mode}")

    return X

# FUN√á√ÉO: Avaliar distribui√ß√£o
def evaluate_distribution(X, mu):
    normalized = X / mu
    normalized = np.clip(normalized, 1e-10, None)
    levels = np.floor(np.log2(normalized)).astype(int)

    unique_levels, counts = np.unique(levels, return_counts=True)
    P_sim = {int(lv): cnt/len(levels) for lv, cnt in zip(unique_levels, counts)}

    # Chi-squared
    chi2 = 0
    for level in P_target.keys():
        obs = P_sim.get(level, 0)
        exp = P_target[level]
        if exp > 0:
            chi2 += (obs - exp)**2 / exp

    accuracy = max(0, 1 - chi2/10.0) * 100
    return accuracy, chi2, P_sim

# CONFIGURA√á√ïES A TESTAR
configs = [
    {
        'name': 'Config 1: AR(3) + Energy-based noise (T=0.1)',
        'boltzmann_mode': 1,
        'temperature': 0.1,
        'use_optimization': True
    },
    {
        'name': 'Config 2: AR(3) + State transitions (T=0.5)',
        'boltzmann_mode': 2,
        'temperature': 0.5,
        'use_optimization': True
    },
    {
        'name': 'Config 3: Pure AR(3) no OU + Boltzmann (T=0.3)',
        'boltzmann_mode': 3,
        'temperature': 0.3,
        'use_optimization': True
    },
    {
        'name': 'Config 4: Level-dependent landscape (T=1.0)',
        'boltzmann_mode': 4,
        'temperature': 1.0,
        'use_optimization': True
    },
    {
        'name': 'Config 5: State transitions low T (T=0.1)',
        'boltzmann_mode': 2,
        'temperature': 0.1,
        'use_optimization': True
    },
    {
        'name': 'Config 6: State transitions high T (T=2.0)',
        'boltzmann_mode': 2,
        'temperature': 2.0,
        'use_optimization': True
    }
]

all_results = []

for cfg in configs:
    print(f"\n{'=' * 70}")
    print(f"TESTANDO: {cfg['name']}")
    print(f"  Mode: {cfg['boltzmann_mode']}")
    print(f"  Temperature: {cfg['temperature']}")
    print(f"{'=' * 70}")

    if cfg['use_optimization']:
        print("\n[OPTIMIZATION] Usando differential evolution...")

        # Fun√ß√£o objetivo
        def objective(params):
            phi = params[:3]
            sigma = params[3]

            # M√∫ltiplas runs para robustez
            accuracies = []
            for _ in range(5):
                X = simulate_ar3_boltzmann(
                    phi, gap_mean, sigma,
                    cfg['temperature'], cfg['boltzmann_mode'],
                    n_steps=15000
                )
                acc, _, _ = evaluate_distribution(X, gap_mean)
                accuracies.append(acc)

            return -np.mean(accuracies)  # Negativo porque minimizamos

        # Bounds
        bounds = [
            (-1.5, 1.5),  # phi1
            (-1.5, 1.5),  # phi2
            (-1.5, 1.5),  # phi3
            (0.01, 0.5)   # sigma
        ]

        # Otimizar
        result = differential_evolution(
            objective, bounds,
            maxiter=60, seed=42, workers=1,
            updating='deferred', atol=1e-6
        )

        best_phi = result.x[:3]
        best_sigma = result.x[3]
        best_accuracy = -result.fun

        print(f"\n[BEST PARAMS]")
        print(f"  œÜ = [{best_phi[0]:.3f}, {best_phi[1]:.3f}, {best_phi[2]:.3f}]")
        print(f"  œÉ = {best_sigma:.3f}")
        print(f"  Accuracy: {best_accuracy:.2f}%")

        # Rodar m√∫ltiplas vezes com melhores par√¢metros
        print(f"\n[VALIDATION] Rodando 20 vezes...")
        accuracies_validation = []
        all_chi2 = []

        for run in range(20):
            X = simulate_ar3_boltzmann(
                best_phi, gap_mean, best_sigma,
                cfg['temperature'], cfg['boltzmann_mode'],
                n_steps=15000
            )
            acc, chi2, P_sim = evaluate_distribution(X, gap_mean)
            accuracies_validation.append(acc)
            all_chi2.append(chi2)

        mean_acc = np.mean(accuracies_validation)
        std_acc = np.std(accuracies_validation)
        max_acc = np.max(accuracies_validation)
        mean_chi2 = np.mean(all_chi2)

        print(f"\n[RESULTS]")
        print(f"  Mean accuracy: {mean_acc:.2f}% ¬± {std_acc:.2f}%")
        print(f"  Max accuracy: {max_acc:.2f}%")
        print(f"  Mean œá¬≤: {mean_chi2:.4f}")

        # √öltima simula√ß√£o para plot
        X_final = simulate_ar3_boltzmann(
            best_phi, gap_mean, best_sigma,
            cfg['temperature'], cfg['boltzmann_mode'],
            n_steps=15000
        )
        _, _, P_final = evaluate_distribution(X_final, gap_mean)

        all_results.append({
            'config': cfg,
            'phi': best_phi.tolist(),
            'sigma': best_sigma,
            'mean_accuracy': mean_acc,
            'std_accuracy': std_acc,
            'max_accuracy': max_acc,
            'mean_chi2': mean_chi2,
            'distribution': P_final,
            'time_series': X_final[:500].tolist()
        })

# COMPARA√á√ÉO FINAL
print(f"\n{'=' * 70}")
print("RESUMO COMPARATIVO")
print(f"{'=' * 70}")

print(f"\n{'Config':<45} {'Mean Acc':<15} {'Max Acc':<10}")
print(f"{'-'*70}")
for res in all_results:
    name = res['config']['name'][:43]
    print(f"{name:<45} {res['mean_accuracy']:>6.2f}% ¬± {res['std_accuracy']:>4.2f}%  {res['max_accuracy']:>6.2f}%")

# Melhor resultado
best_result = max(all_results, key=lambda x: x['max_accuracy'])

print(f"\n{'=' * 70}")
print(f"üèÜ MELHOR RESULTADO")
print(f"{'=' * 70}")
print(f"  Config: {best_result['config']['name']}")
print(f"  Mode: {best_result['config']['boltzmann_mode']}")
print(f"  Temperature: {best_result['config']['temperature']}")
print(f"  œÜ = [{best_result['phi'][0]:.3f}, {best_result['phi'][1]:.3f}, {best_result['phi'][2]:.3f}]")
print(f"  œÉ = {best_result['sigma']:.3f}")
print(f"  Mean accuracy: {best_result['mean_accuracy']:.2f}% ¬± {best_result['std_accuracy']:.2f}%")
print(f"  Max accuracy: {best_result['max_accuracy']:.2f}%")
print(f"  Mean œá¬≤: {best_result['mean_chi2']:.4f}")

print(f"\n[DISTRIBUI√á√ÉO DO MELHOR]")
P_best = best_result['distribution']
for level in sorted(P_best.keys()):
    if P_best[level] > 0.001:
        target = P_target.get(level, 0)
        print(f"  Level {level}: {100*P_best[level]:>5.1f}% (target: {100*target:>5.1f}%)")

# GR√ÅFICOS
fig, axes = plt.subplots(2, 3, figsize=(18, 12))

# 1. Compara√ß√£o de accuracies
ax1 = axes[0, 0]
x_pos = np.arange(len(all_results))
means = [r['mean_accuracy'] for r in all_results]
stds = [r['std_accuracy'] for r in all_results]
maxs = [r['max_accuracy'] for r in all_results]

bars = ax1.bar(x_pos, means, yerr=stds, capsize=5, alpha=0.7, color='blue')
ax1.scatter(x_pos, maxs, color='red', s=100, zorder=5, marker='*', label='Max')
ax1.set_ylabel('Accuracy (%)', fontsize=12)
ax1.set_title('Compara√ß√£o de Accuracies', fontsize=13, fontweight='bold')
ax1.set_xticks(x_pos)
ax1.set_xticklabels([f'C{i+1}' for i in range(len(all_results))], fontsize=10)
ax1.legend()
ax1.grid(True, alpha=0.3, axis='y')
ax1.set_ylim([95, 100])

# 2. Distribui√ß√£o do melhor vs target
ax2 = axes[0, 1]
levels_target = sorted(P_target.keys())
probs_target = [P_target[k] for k in levels_target]
probs_best = [P_best.get(k, 0) for k in levels_target]

x = np.arange(len(levels_target))
width = 0.35
ax2.bar(x - width/2, probs_target, width, label='Riemann', color='black', alpha=0.7)
ax2.bar(x + width/2, probs_best, width, label='Best model', color='blue', alpha=0.7)
ax2.set_xlabel('Level k', fontsize=12)
ax2.set_ylabel('P(k)', fontsize=12)
ax2.set_title(f'Melhor Config: {best_result["max_accuracy"]:.2f}%', fontsize=13, fontweight='bold')
ax2.set_xticks(x)
ax2.set_xticklabels(levels_target)
ax2.legend()
ax2.grid(True, alpha=0.3, axis='y')
ax2.set_yscale('log')

# 3. Time series do melhor
ax3 = axes[0, 2]
X_best = np.array(best_result['time_series'])
ax3.plot(X_best, linewidth=1, alpha=0.7, color='blue')
ax3.axhline(gap_mean, color='r', linestyle='--', linewidth=2, label=f'Œº = {gap_mean:.3f}')
ax3.set_xlabel('Step', fontsize=12)
ax3.set_ylabel('Gap value', fontsize=12)
ax3.set_title('Time Series (Best Config)', fontsize=13, fontweight='bold')
ax3.legend()
ax3.grid(True, alpha=0.3)

# 4. Chi¬≤ comparison
ax4 = axes[1, 0]
chi2_values = [r['mean_chi2'] for r in all_results]
bars = ax4.bar(x_pos, chi2_values, alpha=0.7, color='orange')
ax4.set_ylabel('œá¬≤ (lower is better)', fontsize=12)
ax4.set_title('Chi-squared Comparison', fontsize=13, fontweight='bold')
ax4.set_xticks(x_pos)
ax4.set_xticklabels([f'C{i+1}' for i in range(len(all_results))], fontsize=10)
ax4.grid(True, alpha=0.3, axis='y')

# 5. Distribui√ß√µes log-log
ax5 = axes[1, 1]
for i, res in enumerate(all_results):
    levels = sorted(res['distribution'].keys())
    probs = [res['distribution'][k] for k in levels]
    ax5.plot(levels, probs, 'o-', linewidth=2, markersize=6, alpha=0.7, label=f"C{i+1}")

levels_target = sorted(P_target.keys())
probs_target = [P_target[k] for k in levels_target]
ax5.plot(levels_target, probs_target, 'k^--', linewidth=3, markersize=8,
         label='Riemann', alpha=0.9)
ax5.set_xlabel('Level k', fontsize=12)
ax5.set_ylabel('P(k)', fontsize=12)
ax5.set_title('Todas Distribui√ß√µes (log scale)', fontsize=13, fontweight='bold')
ax5.legend(fontsize=8)
ax5.grid(True, alpha=0.3)
ax5.set_yscale('log')

# 6. Temperature vs Accuracy (para configs com mode 2)
ax6 = axes[1, 2]
mode2_results = [r for r in all_results if r['config']['boltzmann_mode'] == 2]
if len(mode2_results) >= 2:
    temps = [r['config']['temperature'] for r in mode2_results]
    accs = [r['mean_accuracy'] for r in mode2_results]
    ax6.plot(temps, accs, 'o-', linewidth=2, markersize=10, color='red')
    ax6.set_xlabel('Temperature', fontsize=12)
    ax6.set_ylabel('Mean Accuracy (%)', fontsize=12)
    ax6.set_title('Temperature Effect (Mode 2)', fontsize=13, fontweight='bold')
    ax6.grid(True, alpha=0.3)
else:
    ax6.text(0.5, 0.5, 'N/A', ha='center', va='center', fontsize=20)
    ax6.set_title('Temperature Effect', fontsize=13, fontweight='bold')

plt.tight_layout()
plt.savefig('/home/thlinux/relacionalidadegeral/validacao/markov_boltzmann_test.png',
            dpi=300, bbox_inches='tight')
print(f"\n‚úì Gr√°fico salvo: validacao/markov_boltzmann_test.png")

# Salvar resultados
output = {
    'summary': {
        'best_config': best_result['config']['name'],
        'best_mode': best_result['config']['boltzmann_mode'],
        'best_temperature': best_result['config']['temperature'],
        'best_phi': best_result['phi'],
        'best_sigma': best_result['sigma'],
        'best_mean_accuracy': best_result['mean_accuracy'],
        'best_max_accuracy': best_result['max_accuracy'],
        'best_mean_chi2': best_result['mean_chi2']
    },
    'all_results': [
        {
            'name': r['config']['name'],
            'mode': r['config']['boltzmann_mode'],
            'temperature': r['config']['temperature'],
            'phi': r['phi'],
            'sigma': r['sigma'],
            'mean_accuracy': r['mean_accuracy'],
            'std_accuracy': r['std_accuracy'],
            'max_accuracy': r['max_accuracy'],
            'mean_chi2': r['mean_chi2'],
            'distribution': {str(k): v for k, v in r['distribution'].items()}
        }
        for r in all_results
    ],
    'target_distribution': {str(k): v for k, v in P_target.items()}
}

with open('/home/thlinux/relacionalidadegeral/validacao/markov_boltzmann_results.json', 'w') as f:
    json.dump(output, f, indent=2)

print(f"‚úì Resultados salvos: validacao/markov_boltzmann_results.json")

print(f"\n{'=' * 70}")
print("CONCLUS√ÉO")
print(f"{'=' * 70}")

if best_result['max_accuracy'] >= 99.0:
    print(f"\nüéâ SUCESSO! Chegamos em {best_result['max_accuracy']:.2f}%!")
    print(f"   A distribui√ß√£o de Boltzmann foi a chave para quebrar a barreira de 98%.")
    print(f"\n   Configura√ß√£o vencedora:")
    print(f"   - Mode: {best_result['config']['boltzmann_mode']}")
    print(f"   - Temperature: {best_result['config']['temperature']}")
    print(f"   - œÜ = [{best_result['phi'][0]:.3f}, {best_result['phi'][1]:.3f}, {best_result['phi'][2]:.3f}]")
    print(f"   - œÉ = {best_result['sigma']:.3f}")
elif best_result['max_accuracy'] > 98.05:
    print(f"\n‚úì MELHORIA! Chegamos em {best_result['max_accuracy']:.2f}%!")
    print(f"   Melhor que o m√°ximo anterior de 98.05%.")
    print(f"   Boltzmann adicionou {best_result['max_accuracy'] - 98.05:.2f}% de accuracy.")
else:
    print(f"\n‚ö† Resultado: {best_result['max_accuracy']:.2f}%")
    print(f"   N√£o superou o m√°ximo anterior de 98.05%.")
    print(f"   Boltzmann n√£o foi suficiente para quebrar a barreira.")
    print(f"\n   PR√ìXIMO PASSO sugerido:")
    print(f"   - Testar AR(3) PURO (sem OU) conforme solicita√ß√£o do usu√°rio")
    print(f"   - Ou explorar outras distribui√ß√µes f√≠sicas (L√©vy, stretched exponential, etc.)")

print(f"\n{'=' * 70}\n")
